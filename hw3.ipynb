{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "random.seed(1228)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1 [2 балла] Подготовка данных\n",
    "1. Прочитайте размеченные данные Открытого корпуса, используя nltk.corpus.reader.conll.ConllCorpusReader\n",
    "2. Посчитайте количество предложений и число тегов частей речи;\n",
    "3. Сформируйте тестовое и обучающее множество: первые 3/4 данных – обучающее множество;\n",
    "\n",
    "Для каждого слова:\n",
    "1. Определите его окно (слова слева и справа) размера $k$;\n",
    "2. Сформируйте его вектор признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.conll import ConllCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('«', 'PUNCT', '_'), ('Школа', 'NOUN', '_'), ('злословия', 'NOUN', '_'), ('»', 'PUNCT', '_'), ('учит', 'VERB', '_'), ('прикусить', 'VERB', '_'), ('язык', 'NOUN', '_')], [('Сохранится', 'VERB', '_'), ('ли', 'PART', '_'), ('градус', 'NOUN', '_'), ('дискуссии', 'NOUN', '_'), ('в', 'ADP', '_'), ('новом', 'ADJ', '_'), ('сезоне', 'NOUN', '_'), ('?', 'PUNCT', '_')], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['ignore', 'words', 'ignore', 'pos', 'chunk']\n",
    "train_reader = ConllCorpusReader(root = '.', fileids = 'unamb_sent_14_6.conllu', columntypes = columns)\n",
    "\n",
    "\n",
    "sents = train_reader.iob_sents()\n",
    "train_reader.iob_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем количество предложений и разных тэгов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38508"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents) # Предложений в корпусе 38508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PUNCT',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'PUNCT',\n",
       " 'VERB',\n",
       " 'VERB',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " 'PART',\n",
       " 'NOUN',\n",
       " 'NOUN',\n",
       " 'ADP',\n",
       " 'ADJ',\n",
       " 'NOUN',\n",
       " 'PUNCT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#вытащим все тэги\n",
    "pos = [w[1] for sent in sents for w in sent]\n",
    "pos[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вот столько у нас разных тэгов\n",
    "len(set(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# а теперь посмотрим на частотное распределение тэгов \n",
    "from nltk import FreqDist\n",
    "fd_pos = FreqDist(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'ADJ': 47487,\n",
       "          'ADP': 42835,\n",
       "          'ADV': 13079,\n",
       "          'CONJ': 21942,\n",
       "          'DET': 12689,\n",
       "          'INTJ': 452,\n",
       "          'NOUN': 121793,\n",
       "          'NUM': 10173,\n",
       "          'PART': 8923,\n",
       "          'PRON': 9067,\n",
       "          'PROPN': 14889,\n",
       "          'PUNCT': 91323,\n",
       "          'VERB': 41538,\n",
       "          'X': 21393})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, самые частые -- прилагательные и предлоги (о_О)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сформируем тестовую и тренировочную выборки для тэгов\n",
    "\n",
    "Итак, вектор POS у нас есть: `pos`. Теперь сделаем вектор признаков. Для удобства мы решили убрать информацию о границах предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['«',\n",
       " 'школа',\n",
       " 'злословия',\n",
       " '»',\n",
       " 'учит',\n",
       " 'прикусить',\n",
       " 'язык',\n",
       " 'сохранится',\n",
       " 'ли',\n",
       " 'градус',\n",
       " 'дискуссии',\n",
       " 'в',\n",
       " 'новом',\n",
       " 'сезоне',\n",
       " '?',\n",
       " 'великолепная',\n",
       " '«',\n",
       " 'школа',\n",
       " 'злословия',\n",
       " '»']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [word[0].lower() for sent in sents for word in sent]\n",
    "words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлечение признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddingsPath = './wiki.ru.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniq_words = set(words)\n",
    "def extract_embeddings(path):\n",
    "    embeddings = {}\n",
    "    with open(embeddingsPath) as f:\n",
    "        for line in f:\n",
    "            word, vec = line.split(' ', 1)\n",
    "            if word in uniq_words:\n",
    "                embeddings[word] = [float(num) for num in vec.split()]\n",
    "    return embeddings\n",
    "\n",
    "embeddings = extract_embeddings(embeddingsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.32315,\n",
       " 0.91456,\n",
       " 0.13797,\n",
       " 0.61075,\n",
       " -0.28406,\n",
       " -0.47918,\n",
       " -0.27341,\n",
       " 0.17947,\n",
       " 0.54726,\n",
       " -0.47914,\n",
       " -0.20418,\n",
       " 0.12833,\n",
       " 0.1399,\n",
       " 0.26005,\n",
       " 0.53394]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['школа'][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings['школа'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a strange fix\n",
    "embeddings['«'] = embeddings['\"']\n",
    "embeddings['»'] = embeddings['\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создаём вектора для начала и конца (и плэйсхолдер на случай если в эмбеддингах слова нет)\n",
    "MOF = [0] * 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k == 2\n",
    "def featues_k2(tokens):\n",
    "    features = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word in embeddings:\n",
    "            cur_word = embeddings[word]\n",
    "        else:\n",
    "            cur_word = MOF\n",
    "        if i > 0 and tokens[i - 1] in embeddings:\n",
    "            prev_word = embeddings[tokens[i - 1]]\n",
    "        else:\n",
    "            prev_word = MOF\n",
    "        if i < len(tokens) - 1 and tokens[i + 1] in embeddings:\n",
    "            next_word = embeddings[tokens[i + 1]]\n",
    "        else:\n",
    "            next_word = MOF\n",
    "        features.append(cur_word + prev_word + next_word)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = featues_k2(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features) == len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343185\n",
      "114398\n"
     ]
    }
   ],
   "source": [
    "boundary = (len(pos) // 4) * 3\n",
    "y_train = pos[:boundary]\n",
    "X_train = features[:boundary]\n",
    "y_test = pos[boundary:]\n",
    "X_test = features[boundary:]\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343185,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2 [4 баллов] Архитектура нейронной сети\n",
    "\n",
    "Архитектура нейронной сети состоит из следующих слов:\n",
    "1. Входной слой: нейронная сеть получает на вход вектор признаков, состоящий из $k$ конкатенированных эмбеддингов;/\n",
    "2. Скрытый слой: $n_h$ нейронов и нелинейная функция активации $\\theta$;\n",
    "3. Выходной слой:  $|T|$ нейронов для итоговой классификации.\n",
    "\n",
    "Обучите нейронную сеть на обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_filter = 250\n",
    "hidden_dims = 250\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(list(set(pos)))\n",
    "y_train = np_utils.to_categorical(le.transform(y_train), 14)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем нейросетку :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308866 samples, validate on 34319 samples\n",
      "Epoch 1/10\n",
      "308866/308866 [==============================] - 26s 86us/step - loss: 0.2172 - acc: 0.9328 - val_loss: 0.2374 - val_acc: 0.9273\n",
      "Epoch 2/10\n",
      "308866/308866 [==============================] - 22s 72us/step - loss: 0.1260 - acc: 0.9595 - val_loss: 0.2218 - val_acc: 0.9304\n",
      "Epoch 3/10\n",
      "308866/308866 [==============================] - 22s 71us/step - loss: 0.0981 - acc: 0.9677 - val_loss: 0.2385 - val_acc: 0.9303\n",
      "Epoch 4/10\n",
      "308866/308866 [==============================] - 24s 77us/step - loss: 0.0794 - acc: 0.9735 - val_loss: 0.2543 - val_acc: 0.9320\n",
      "Epoch 5/10\n",
      "308866/308866 [==============================] - 21s 69us/step - loss: 0.0671 - acc: 0.9774 - val_loss: 0.2714 - val_acc: 0.9323\n",
      "Epoch 6/10\n",
      "308866/308866 [==============================] - 23s 74us/step - loss: 0.0570 - acc: 0.9806 - val_loss: 0.2781 - val_acc: 0.9327\n",
      "Epoch 7/10\n",
      "308866/308866 [==============================] - 24s 77us/step - loss: 0.0500 - acc: 0.9830 - val_loss: 0.3095 - val_acc: 0.9301\n",
      "Epoch 8/10\n",
      "308866/308866 [==============================] - 23s 73us/step - loss: 0.0447 - acc: 0.9846 - val_loss: 0.3343 - val_acc: 0.9281\n",
      "Epoch 9/10\n",
      "308866/308866 [==============================] - 23s 74us/step - loss: 0.0403 - acc: 0.9862 - val_loss: 0.3498 - val_acc: 0.9292\n",
      "Epoch 10/10\n",
      "308866/308866 [==============================] - 23s 74us/step - loss: 0.0378 - acc: 0.9868 - val_loss: 0.3603 - val_acc: 0.9296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d144ac8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(900, ), activation='relu'))\n",
    "model.add(Dense(14, activation = 'softmax')) # софтмакс для классификации\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=nb_epoch,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, обучили!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3 [1 балл] Оценка качества\n",
    "\n",
    "Протестируйте нейронную сеть на тестовых данных. Используйте accuracy для оценки качества модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n"
     ]
    }
   ],
   "source": [
    "y_test = pos[boundary:]\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ADJ       0.96      0.93      0.94     12573\n",
      "        ADP       1.00      0.99      0.99     10039\n",
      "        ADV       0.92      0.89      0.91      3042\n",
      "       CONJ       0.97      0.98      0.97      5510\n",
      "        DET       0.95      0.97      0.96      2794\n",
      "       INTJ       0.65      0.60      0.62       106\n",
      "       NOUN       0.96      0.98      0.97     32653\n",
      "        NUM       0.70      0.79      0.74      2283\n",
      "       PART       0.94      0.92      0.93      1906\n",
      "       PRON       0.98      0.98      0.98      1896\n",
      "      PROPN       0.86      0.78      0.81      2734\n",
      "      PUNCT       0.98      0.97      0.97     23948\n",
      "       VERB       0.97      0.97      0.97      9458\n",
      "          X       0.68      0.67      0.67      5456\n",
      "\n",
      "avg / total       0.94      0.94      0.94    114398\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9442735012849875"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Похоже, получилось довольно неплохо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4 [1 балл] Оптимизация гиперпарметров\n",
    "\n",
    "В эксперименте участвуют следующие гиперпараметры:\n",
    "* $k$ – размер окна;\n",
    "* $n_h$ – число нейронов на скрытом слое;\n",
    "* $\\theta$ – вид функции активации.\n",
    "\n",
    "Оцените их влияние на качество модели. Как увеличение окна или числа нейронов влияет на итоговый показатель качества? Зависит ли итоговый показатель качества от функции активации на скрытом слое? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# фц которая перебирает разные параметры\n",
    "def train_model(n, theta):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n, input_shape=(3*300,), activation = theta)) # скрытый слой; первый аргумент - размерность аутпута\n",
    "    model.add(Dense(14, activation = 'softmax')) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 5 [2 балла] Анализ ошибок\n",
    "1. Приведите примеры из тестового множества, на которых нейронная сеть ошибается. Объясните, почему возникают ошибки.\n",
    "2. Протестируйте нейронную сеть на произвольном предложении (не из тестовых данных). Возникают ли ошибки? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word \t\t true \t\t predicted\n",
      "какой-то \t\t DET \t\t X\n",
      "травлю \t\t VERB \t\t NOUN\n",
      "адидас \t\t X \t\t PROPN\n",
      "что \t\t CONJ \t\t PART\n",
      ": \t\t PUNCT \t\t X\n",
      "1999 \t\t NUM \t\t X\n",
      "теде \t\t PROPN \t\t X\n",
      "права \t\t ADJ \t\t NOUN\n",
      "насчет \t\t ADP \t\t VERB\n",
      "%) \t\t PUNCT \t\t X\n",
      "заплутал \t\t VERB \t\t NUM\n",
      "петера \t\t PROPN \t\t X\n",
      "психотест \t\t X \t\t NOUN\n",
      "как \t\t CONJ \t\t ADV\n",
      "надо \t\t ADV \t\t VERB\n",
      "программно \t\t ADV \t\t NOUN\n",
      "общем \t\t ADJ \t\t X\n",
      "кладу \t\t VERB \t\t NOUN\n",
      "рядом \t\t ADV \t\t ADP\n",
      ":) \t\t PUNCT \t\t NUM\n"
     ]
    }
   ],
   "source": [
    "# 20 токенов, на которых классификатор ошибается\n",
    "count = 0\n",
    "print('word', '\\t\\t', 'true', '\\t\\t', 'predicted')\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] != y_pred[i]:\n",
    "        count += 1\n",
    "        print(words[boundary+i], '\\t\\t', y_test[i], '\\t\\t', y_pred[i])\n",
    "    if count == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, у классификатора проблемы со смайликами (неудивительно, всё-таки, это на просто пунктуация)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'PUNCT', 'PRON', 'X', 'NUM', 'CONJ', 'NOUN', 'VERB',\n",
       "       'PUNCT'], dtype='<U5')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_sent = 'дорогая , я что-то нажала и всё исчезло !'.split()\n",
    "fiches = featues_k2(custom_sent)\n",
    "pred = model.predict_classes(np.array(fiches))\n",
    "le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не впечатляет... Но большая часть токенов предсказана правильно."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
