{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3 [10 баллов]\n",
    "\n",
    "\n",
    "# До 27.03.18 23:59\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предварительная\n",
    "\n",
    "### Предварительная обработка данных [2 балла]\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 2943\n"
     ]
    }
   ],
   "source": [
    "# прочитаем файлы\n",
    "female = open('female.txt', 'r').read().split('\\n')\n",
    "male = open('male.txt', 'r').read().split('\\n')\n",
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удаляем неоднозначные имена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# найдем имена, которые одинаковы для двух списков\n",
    "result = set(female) & set(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# удалим их!\n",
    "female = list(set(female) - result)\n",
    "male = list(set(male) - result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 2578\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sansone', 'Rolland', 'Morley', 'Keefe', 'Howard', 'Pierre', 'Bealle', 'Fidel', 'Benton', 'Gallagher', 'Jakob', 'Wyatt', 'Padraig', 'Bryan', 'Agamemnon', 'Sayer', 'Hunter', 'Redford', 'Lawrence', 'Parker', 'Tad', 'Spense', 'Barde', 'Raynor', 'Forrest', 'Che', 'Antoni', 'Torrance', 'Lenard', 'Gibb', 'Niels', 'Rand', 'Neddy', 'Marten', 'Tann', 'Weber', 'Esau', 'Kenn', 'Corwin', 'Derby', 'John', 'Tremaine', 'Erek', 'Griffith', 'Haydon', 'Ellwood', 'Hamlen', 'Thaxter', 'Matt', 'Barclay', 'Sheppard', 'Jefferson', 'Leonidas', 'Hiram', 'Piet', 'Janos', 'Temp', 'Barnabas', 'Batholomew', 'Kendal', 'Wait', 'Remus', 'Forest', 'Samson', 'Rod', 'Arvie', 'Fernando', 'Ulrich', 'Nate', 'Rodolph', 'Alfonse', 'Barty', 'Briggs', 'Spence', 'Ric', 'Luis', 'Job', 'Gavin', 'Wyn', 'Fremont', 'Silvan', 'Nathanael', 'Jermayne', 'Will', 'Aguinaldo', 'Bryce', 'Parry', 'Cliff', 'Nevin', 'Vaclav', 'Archon', 'Rutherford', 'Rice', 'Xymenes', 'Berchtold', 'Maynord', 'Si', 'Orville', 'Mitchel', 'Clive']\n"
     ]
    }
   ],
   "source": [
    "print(male[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Балансируем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oversampling!\n",
    "missing = len(female) - len(male)\n",
    "male += male[:missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffling\n",
    "import random\n",
    "random.shuffle(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 4636\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7416 1856 7416 1856\n"
     ]
    }
   ],
   "source": [
    "boundary = int(len(female) * 0.8)\n",
    "x_train = female[:boundary] + male[:boundary]\n",
    "x_test = female[boundary:] + male[boundary:]\n",
    "y_train = ['female'] * (boundary ) + ['male'] * (boundary)\n",
    "y_test = ['female'] * (len(x_test)//2) + ['male'] * (len(x_test)//2)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>Ardys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Gabrielle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>Sukey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>Koo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Pauli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class       name\n",
       "0  female      Ardys\n",
       "1  female  Gabrielle\n",
       "2  female      Sukey\n",
       "3  female        Koo\n",
       "4  female      Pauli"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "index = random.sample(range(len(x_train)), len(x_train))\n",
    "df = pd.DataFrame({'name': x_train, 'class': y_train})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>Vitia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Cynthia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>Cybel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Terrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Crystal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class     name\n",
       "0  female    Vitia\n",
       "1  female  Cynthia\n",
       "2  female    Cybel\n",
       "3    male   Terrel\n",
       "4  female  Crystal"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перемешаем\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 2. Базовая \n",
    "\n",
    "### Базовый метод классификации [3 балла]\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим три бейзлайновые модели на символьных 2, 3, и 4-граммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# биграммы\n",
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(2, 2), analyzer='char')),\n",
    "    ('nb', MultinomialNB())]\n",
    ")\n",
    "ppl.fit(x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.74      0.76      0.75       928\n",
      "       male       0.76      0.74      0.75       928\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1856\n",
      "\n",
      "0.748922413793\n"
     ]
    }
   ],
   "source": [
    "labels = ppl.predict(x_test)\n",
    "print(classification_report(y_test, labels))\n",
    "print(accuracy_score(y_test, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# триграммы\n",
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(3, 3), analyzer='char')),\n",
    "    ('nb', MultinomialNB())]\n",
    ")\n",
    "ppl.fit(x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.79      0.83      0.81       928\n",
      "       male       0.82      0.78      0.80       928\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1856\n",
      "\n",
      "0.806573275862\n"
     ]
    }
   ],
   "source": [
    "labels = ppl.predict(x_test)\n",
    "print(classification_report(y_test, labels))\n",
    "print(accuracy_score(y_test, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(4, 4), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# квадриграммы\n",
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(4, 4), analyzer='char')),\n",
    "    ('nb', MultinomialNB())]\n",
    ")\n",
    "ppl.fit(x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.81      0.88      0.84       928\n",
      "       male       0.87      0.79      0.83       928\n",
      "\n",
      "avg / total       0.84      0.84      0.84      1856\n",
      "\n",
      "0.836745689655\n"
     ]
    }
   ],
   "source": [
    "labels = ppl.predict(x_test)\n",
    "print(classification_report(y_test, labels))\n",
    "print(accuracy_score(y_test, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, чем больше n, тем выше значение всех метрик.\n",
    "Попробуем, из любопытства, n=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(5, 5), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пентаграммы (извините)\n",
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(ngram_range=(5, 5), analyzer='char')),\n",
    "    ('nb', MultinomialNB())]\n",
    ")\n",
    "ppl.fit(x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.73      0.93      0.82       928\n",
      "       male       0.90      0.66      0.77       928\n",
      "\n",
      "avg / total       0.82      0.80      0.79      1856\n",
      "\n",
      "0.796336206897\n"
     ]
    }
   ],
   "source": [
    "labels = ppl.predict(x_test)\n",
    "print(classification_report(y_test, labels))\n",
    "print(accuracy_score(y_test, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При n=5 качество перестало расти.\n",
    "Теперь проанализируем ошибки для лучшей модели (4-граммы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 3. Нейросетевая \n",
    "\n",
    "### Нейронная сеть [5 баллов]\n",
    "\n",
    "\n",
    "Используйте  реккурентную нейронную сеть с  LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM).  У нейронной сети один выход, определяющий класс имени. \n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$ – то есть, используется one hot encoding.  \n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами. \n",
    "\n",
    "Сравните результаты классификации разными методами. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совсем не получается запрограммировать нейронную сеть самостоятельно, обратитесь к туториалу тут: https://github.com/divamgupta/lstm-gender-predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### делаем one-hot-encoded данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = sorted(set(''.join(df['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(df['name'].map(lambda x: len(x)))\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(data, letters, maxlen):\n",
    "    '''np.array вида (кол-во примеров х бинарная матрица размера (количество букв в алфавите × максимальная длина имени)'''\n",
    "    res = np.zeros((len(data), maxlen, len(letters)))\n",
    "    for i in range(len(data)): # по именам\n",
    "        for l in range(len(data[i])): # по буквам\n",
    "            res[i][l][letters.index(data[i][l])] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7416, 15, 55)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = one_hot(x_train, alphabet, maxlen)\n",
    "y_train = np.array(list(map(lambda x: (1, 0) if x=='female' else (0, 1), y_train)))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### а теперь собственно модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = one_hot(x_test, alphabet, maxlen)\n",
    "y_test = to_categorical(np.array(list(map(lambda x: 0 if x=='female' else 1, y_test))), num_classes=2)\n",
    "preds = model.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.82      0.80       928\n",
      "          1       0.81      0.78      0.79       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.796875\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.81      0.80       928\n",
      "          1       0.81      0.77      0.79       928\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1856\n",
      "\n",
      "0.7914870689655172\n"
     ]
    }
   ],
   "source": [
    "# другие методы\n",
    "# добавляем дропаут\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds = model.predict(X_test, verbose=0)\n",
    "preds = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80       928\n",
      "          1       0.80      0.80      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.8033405172413793\n"
     ]
    }
   ],
   "source": [
    "# меняем значение дропаута\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds2 = model.predict(X_test, verbose=0)\n",
    "preds2 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds2)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds2))\n",
    "print(accuracy_score(y_test, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.82      0.79       928\n",
      "          1       0.80      0.75      0.78       928\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1856\n",
      "\n",
      "0.7855603448275862\n"
     ]
    }
   ],
   "source": [
    "# один LSTM-слой\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = False, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds3 = model.predict(X_test, verbose=0)\n",
    "preds3 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds3)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds3))\n",
    "print(accuracy_score(y_test, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.82      0.81       928\n",
      "          1       0.81      0.79      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.8033405172413793\n"
     ]
    }
   ],
   "source": [
    "# меняем количество узлов\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds4 = model.predict(X_test, verbose=0)\n",
    "preds4 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds4)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds4))\n",
    "print(accuracy_score(y_test, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80       928\n",
      "          1       0.80      0.80      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.7990301724137931\n"
     ]
    }
   ],
   "source": [
    "# меняем количество слоёв\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds5 = model.predict(X_test, verbose=0)\n",
    "preds5 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds5)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds5))\n",
    "print(accuracy_score(y_test, preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог: ничего не меняется! Только лучше два LSTM-слоя, чем один. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsbeth [1. 0.]\n",
      "Oreste [1. 0.]\n",
      "Jonell [1. 0.]\n",
      "Violet [1. 0.]\n",
      "Margery [1. 0.]\n",
      "Shel [1. 0.]\n",
      "Ingaborg [1. 0.]\n",
      "Nicol [1. 0.]\n",
      "Deerdre [1. 0.]\n",
      "Hali [1. 0.]\n",
      "Venus [1. 0.]\n",
      "Jenifer [1. 0.]\n",
      "Orel [1. 0.]\n",
      "Rakel [1. 0.]\n",
      "Deirdre [1. 0.]\n",
      "Wanda [1. 0.]\n",
      "Taryn [1. 0.]\n",
      "Nance [1. 0.]\n",
      "Merci [1. 0.]\n",
      "Prudence [1. 0.]\n",
      "Becky [1. 0.]\n",
      "Beilul [1. 0.]\n",
      "Bekki [1. 0.]\n",
      "Idell [1. 0.]\n",
      "Ines [1. 0.]\n",
      "Carrol [1. 0.]\n",
      "Pier [1. 0.]\n",
      "Katheryn [1. 0.]\n",
      "Vere [1. 0.]\n",
      "Burta [1. 0.]\n",
      "Gates [1. 0.]\n",
      "Marjy [1. 0.]\n",
      "Vicky [1. 0.]\n",
      "Shandy [1. 0.]\n",
      "Valma [1. 0.]\n",
      "Nova [1. 0.]\n",
      "Raven [1. 0.]\n",
      "Damaris [1. 0.]\n",
      "Ame [1. 0.]\n",
      "Mavis [1. 0.]\n",
      "Mitzi [1. 0.]\n",
      "Inger [1. 0.]\n",
      "Brunhilde [1. 0.]\n",
      "Milicent [1. 0.]\n",
      "Mommy [1. 0.]\n",
      "Deloris [1. 0.]\n",
      "Sukey [1. 0.]\n",
      "Farand [1. 0.]\n",
      "Harri [1. 0.]\n",
      "Greer [1. 0.]\n",
      "Francesca [1. 0.]\n",
      "Steffane [1. 0.]\n",
      "Kimberly [1. 0.]\n",
      "Audre [1. 0.]\n",
      "Ardith [1. 0.]\n",
      "Midge [1. 0.]\n",
      "Stormi [1. 0.]\n",
      "Marijo [1. 0.]\n",
      "Meghan [1. 0.]\n",
      "Beatriz [1. 0.]\n",
      "Betty [1. 0.]\n",
      "Mignon [1. 0.]\n",
      "Tiff [1. 0.]\n",
      "Sharl [1. 0.]\n",
      "Windy [1. 0.]\n",
      "Sileas [1. 0.]\n",
      "Cher [1. 0.]\n",
      "Trudey [1. 0.]\n",
      "Storey [1. 0.]\n",
      "Eadith [1. 0.]\n",
      "Gwendolyn [1. 0.]\n",
      "Jacynth [1. 0.]\n",
      "Reggi [1. 0.]\n",
      "Vikkie [1. 0.]\n",
      "Glennis [1. 0.]\n",
      "Suzie [1. 0.]\n",
      "Sheryl [1. 0.]\n",
      "Ambur [1. 0.]\n",
      "Prue [1. 0.]\n",
      "Maris [1. 0.]\n",
      "Riki [1. 0.]\n",
      "Dorris [1. 0.]\n",
      "Estell [1. 0.]\n",
      "Tabbi [1. 0.]\n",
      "Vicki [1. 0.]\n",
      "Pauly [1. 0.]\n",
      "Tamar [1. 0.]\n",
      "Ermengarde [1. 0.]\n",
      "Inge [1. 0.]\n",
      "Jewel [1. 0.]\n",
      "Joann [1. 0.]\n",
      "Dotty [1. 0.]\n",
      "Madlen [1. 0.]\n",
      "Batsheva [1. 0.]\n",
      "Hatty [1. 0.]\n",
      "Robbi [1. 0.]\n",
      "Mercedes [1. 0.]\n",
      "Mallory [1. 0.]\n",
      "Maryrose [1. 0.]\n",
      "Dode [1. 0.]\n",
      "Robyn [1. 0.]\n",
      "Dawn [1. 0.]\n",
      "Marys [1. 0.]\n",
      "Tove [1. 0.]\n",
      "Consuelo [1. 0.]\n",
      "Marcy [1. 0.]\n",
      "Alyson [1. 0.]\n",
      "Rosamund [1. 0.]\n",
      "Bamby [1. 0.]\n",
      "Caron [1. 0.]\n",
      "Sapphire [1. 0.]\n",
      "Becca [1. 0.]\n",
      "Bridgett [1. 0.]\n",
      "Nariko [1. 0.]\n",
      "Genevieve [1. 0.]\n",
      "Sheril [1. 0.]\n",
      "Ester [1. 0.]\n",
      "Mildrid [1. 0.]\n",
      "Nicholle [1. 0.]\n",
      "Constancy [1. 0.]\n",
      "Elonore [1. 0.]\n",
      "Hedi [1. 0.]\n",
      "Nicolle [1. 0.]\n",
      "Dorthy [1. 0.]\n",
      "Olva [1. 0.]\n",
      "Zara [1. 0.]\n",
      "Yoko [1. 0.]\n",
      "Joyous [1. 0.]\n",
      "Noell [1. 0.]\n",
      "Leonore [1. 0.]\n",
      "Babs [1. 0.]\n",
      "Ursa [1. 0.]\n",
      "Suzi [1. 0.]\n",
      "Riannon [1. 0.]\n",
      "Wilone [1. 0.]\n",
      "Easter [1. 0.]\n",
      "Andromache [1. 0.]\n",
      "Dulci [1. 0.]\n",
      "Bee [1. 0.]\n",
      "Lamb [1. 0.]\n",
      "Tish [1. 0.]\n",
      "Prudy [1. 0.]\n",
      "Truda [1. 0.]\n",
      "Diahann [1. 0.]\n",
      "Megen [1. 0.]\n",
      "Stoddard [1. 0.]\n",
      "Taffy [1. 0.]\n",
      "Vi [1. 0.]\n",
      "Brigid [1. 0.]\n",
      "Bab [1. 0.]\n",
      "Dusty [1. 0.]\n",
      "Ethelind [1. 0.]\n",
      "Charlot [1. 0.]\n",
      "Hermione [1. 0.]\n",
      "Orly [1. 0.]\n",
      "Avivah [1. 0.]\n",
      "Gwendolen [1. 0.]\n",
      "Fabrice [1. 0.]\n",
      "Malory [1. 0.]\n",
      "Heather [1. 0.]\n",
      "Flower [1. 0.]\n",
      "Vikky [1. 0.]\n",
      "Sue [1. 0.]\n",
      "Jorry [1. 0.]\n",
      "Marris [1. 0.]\n",
      "Ulla [1. 0.]\n",
      "Arden [1. 0.]\n",
      "Ricca [1. 0.]\n",
      "Olwen [1. 0.]\n",
      "Adore [1. 0.]\n",
      "Shawna [1. 0.]\n",
      "Gaynor [1. 0.]\n",
      "Susann [1. 0.]\n",
      "Judi [1. 0.]\n",
      "Ruth [1. 0.]\n",
      "Gerty [1. 0.]\n",
      "Jessamyn [1. 0.]\n",
      "Hedwig [1. 0.]\n",
      "Tammi [1. 0.]\n",
      "Suzan [1. 0.]\n",
      "Sharyl [1. 0.]\n",
      "Charis [1. 0.]\n",
      "Petronille [1. 0.]\n",
      "Leanor [1. 0.]\n",
      "Starr [1. 0.]\n",
      "Dwaine [0. 1.]\n",
      "Tanny [0. 1.]\n",
      "Kent [0. 1.]\n",
      "Matthieu [0. 1.]\n",
      "Noble [0. 1.]\n",
      "Giovanne [0. 1.]\n",
      "Samuele [0. 1.]\n",
      "Scottie [0. 1.]\n",
      "Constantin [0. 1.]\n",
      "Mathias [0. 1.]\n",
      "Gabriele [0. 1.]\n",
      "Beale [0. 1.]\n",
      "Arne [0. 1.]\n",
      "Neale [0. 1.]\n",
      "Arel [0. 1.]\n",
      "Mayer [0. 1.]\n",
      "Conroy [0. 1.]\n",
      "Lonny [0. 1.]\n",
      "Sebastien [0. 1.]\n",
      "Israel [0. 1.]\n",
      "Mattias [0. 1.]\n",
      "Gabe [0. 1.]\n",
      "Arne [0. 1.]\n",
      "Tanney [0. 1.]\n",
      "Hussein [0. 1.]\n",
      "Sebastiano [0. 1.]\n",
      "Carlyle [0. 1.]\n",
      "Gordan [0. 1.]\n",
      "Boniface [0. 1.]\n",
      "Alastair [0. 1.]\n",
      "Partha [0. 1.]\n",
      "Manny [0. 1.]\n",
      "Gabe [0. 1.]\n",
      "Meier [0. 1.]\n",
      "Nelsen [0. 1.]\n",
      "Brian [0. 1.]\n",
      "Stevie [0. 1.]\n",
      "Erny [0. 1.]\n",
      "Colin [0. 1.]\n",
      "Hyatt [0. 1.]\n",
      "Alan [0. 1.]\n",
      "Morley [0. 1.]\n",
      "Cain [0. 1.]\n",
      "Felipe [0. 1.]\n",
      "Paddie [0. 1.]\n",
      "Jake [0. 1.]\n",
      "Clinten [0. 1.]\n",
      "Lucian [0. 1.]\n",
      "Tanney [0. 1.]\n",
      "Joshua [0. 1.]\n",
      "Kennedy [0. 1.]\n",
      "Elijah [0. 1.]\n",
      "Natale [0. 1.]\n",
      "Cleland [0. 1.]\n",
      "Florian [0. 1.]\n",
      "Kin [0. 1.]\n",
      "Michael [0. 1.]\n",
      "Jonny [0. 1.]\n",
      "Adair [0. 1.]\n",
      "Jonny [0. 1.]\n",
      "Solly [0. 1.]\n",
      "Roni [0. 1.]\n",
      "Clive [0. 1.]\n",
      "Obadiah [0. 1.]\n",
      "Augie [0. 1.]\n",
      "Danie [0. 1.]\n",
      "Dougie [0. 1.]\n",
      "Broddie [0. 1.]\n",
      "Brinkley [0. 1.]\n",
      "Sollie [0. 1.]\n",
      "Aditya [0. 1.]\n",
      "Micheil [0. 1.]\n",
      "Lennie [0. 1.]\n",
      "Avi [0. 1.]\n",
      "Johnathan [0. 1.]\n",
      "Jamey [0. 1.]\n",
      "Sebastiano [0. 1.]\n",
      "Len [0. 1.]\n",
      "Israel [0. 1.]\n",
      "Nolan [0. 1.]\n",
      "Archie [0. 1.]\n",
      "Louie [0. 1.]\n",
      "Nealy [0. 1.]\n",
      "Cobbie [0. 1.]\n",
      "Mace [0. 1.]\n",
      "Natale [0. 1.]\n",
      "Barnabe [0. 1.]\n",
      "Keil [0. 1.]\n",
      "Pascale [0. 1.]\n",
      "Duane [0. 1.]\n",
      "Nikita [0. 1.]\n",
      "Dabney [0. 1.]\n",
      "Sinclare [0. 1.]\n",
      "Andri [0. 1.]\n",
      "Tye [0. 1.]\n",
      "Dylan [0. 1.]\n",
      "Abe [0. 1.]\n",
      "Hyatt [0. 1.]\n",
      "Jermayne [0. 1.]\n",
      "Andreas [0. 1.]\n",
      "Elias [0. 1.]\n",
      "Guy [0. 1.]\n",
      "Clint [0. 1.]\n",
      "Lemmie [0. 1.]\n",
      "Davey [0. 1.]\n",
      "Isaak [0. 1.]\n",
      "Emilio [0. 1.]\n",
      "Blayne [0. 1.]\n",
      "Alastair [0. 1.]\n",
      "Dabney [0. 1.]\n",
      "Mortie [0. 1.]\n",
      "Bennett [0. 1.]\n",
      "Jonathan [0. 1.]\n",
      "Dyson [0. 1.]\n",
      "Ari [0. 1.]\n",
      "Jimmy [0. 1.]\n",
      "Dino [0. 1.]\n",
      "Lloyd [0. 1.]\n",
      "Lay [0. 1.]\n",
      "Chase [0. 1.]\n",
      "Thorndike [0. 1.]\n",
      "Voltaire [0. 1.]\n",
      "Tremain [0. 1.]\n",
      "Jeremie [0. 1.]\n",
      "Dimitri [0. 1.]\n",
      "Chrisy [0. 1.]\n",
      "Glynn [0. 1.]\n",
      "Gere [0. 1.]\n",
      "Chip [0. 1.]\n",
      "Adlai [0. 1.]\n",
      "Dante [0. 1.]\n",
      "Maximilian [0. 1.]\n",
      "Riley [0. 1.]\n",
      "Ulysses [0. 1.]\n",
      "Clarke [0. 1.]\n",
      "Zollie [0. 1.]\n",
      "Tyrone [0. 1.]\n",
      "Amory [0. 1.]\n",
      "Garey [0. 1.]\n",
      "Corbin [0. 1.]\n",
      "Amery [0. 1.]\n",
      "Izzy [0. 1.]\n",
      "Paddie [0. 1.]\n",
      "Nathanael [0. 1.]\n",
      "Dwayne [0. 1.]\n",
      "Chaddie [0. 1.]\n",
      "Irvine [0. 1.]\n",
      "Stanley [0. 1.]\n",
      "Tannie [0. 1.]\n",
      "Levi [0. 1.]\n",
      "Noe [0. 1.]\n",
      "Lloyd [0. 1.]\n",
      "Dudley [0. 1.]\n",
      "Doyle [0. 1.]\n",
      "Jake [0. 1.]\n",
      "Isidore [0. 1.]\n",
      "Zacharia [0. 1.]\n",
      "Dimitry [0. 1.]\n",
      "Hezekiah [0. 1.]\n",
      "Rollin [0. 1.]\n",
      "Rustie [0. 1.]\n",
      "Fonsie [0. 1.]\n",
      "Clyde [0. 1.]\n",
      "Pasquale [0. 1.]\n",
      "Blare [0. 1.]\n",
      "Brady [0. 1.]\n",
      "Bentley [0. 1.]\n",
      "Jory [0. 1.]\n",
      "Grady [0. 1.]\n",
      "Huntlee [0. 1.]\n",
      "Toddie [0. 1.]\n",
      "Mateo [0. 1.]\n",
      "Neddie [0. 1.]\n",
      "Chrisy [0. 1.]\n",
      "Elroy [0. 1.]\n",
      "Barney [0. 1.]\n",
      "Ferdinand [0. 1.]\n",
      "Kalil [0. 1.]\n",
      "Dylan [0. 1.]\n",
      "Dean [0. 1.]\n",
      "Keene [0. 1.]\n",
      "Christiano [0. 1.]\n",
      "Silvain [0. 1.]\n",
      "Sebastian [0. 1.]\n",
      "Charley [0. 1.]\n",
      "Izaak [0. 1.]\n",
      "Keene [0. 1.]\n",
      "Gere [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    if all(y_test[i] != preds5[i]):\n",
    "        print(x_test[i], y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 4. Сомнительная \n",
    "\n",
    "### Визуализация [5 баллов]\n",
    "\n",
    "Теперь будем использовать другое представление имени: замените каждый символ на его id. Теперь каждое имя – это последовательность длины maxlen. Вы будете обучать эмбеддинги для каждого символа, для этого добавьте в нейронную сети слой Embedding(trainable = True). Как изменение представления символа повлияет на качество классификации?\n",
    "\n",
    "\n",
    "Побочным продуктом обучения нейронной сети будут эмбеддинги символов – 26 векторов для всех букв латинского алфавита (+ другие символы, которые вы посчитали нужным использовать). Попробуйте использовать разные методы снижения размерности – SVD или TSNE – и изобразить точки, соответствующие разным символам, на плоскости. Получаются ли осмысленные и интерпретируемые кластеры?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
