{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3 [10 баллов]\n",
    "\n",
    "\n",
    "# До 27.03.18 23:59\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предварительная\n",
    "\n",
    "### Предварительная обработка данных [2 балла]\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 2943\n"
     ]
    }
   ],
   "source": [
    "# прочитаем файлы\n",
    "female = open('female.txt', 'r').read().split('\\n')\n",
    "male = open('male.txt', 'r').read().split('\\n')\n",
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удаляем неоднозначные имена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# найдем имена, которые одинаковы для двух списков\n",
    "result = set(female) & set(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# удалим их!\n",
    "female = list(set(female) - result)\n",
    "male = list(set(male) - result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 2578\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rodge', 'Rollin', 'Izzy', 'Trenton', 'Samuel', 'Gasper', 'Solomon', 'Corby', 'Rabbi', 'Zebedee', 'Agustin', 'Bjorn', 'Bogart', 'Traver', 'Raymundo', 'Gerhardt', 'Diego', 'Hamlet', 'Warde', 'Rockwell', 'Reuben', 'Napoleon', 'Bernd', 'Beck', 'Torrin', 'Hezekiah', 'Templeton', 'Maxwell', 'Benson', 'Isaak', 'Izaak', 'Rolph', 'Sol', 'Rutger', 'Rodrigo', 'Salomon', 'Simeon', 'Broddie', 'Rik', 'Ingemar', 'Ingelbert', 'Harrison', 'Rolando', 'Lincoln', 'Forrest', 'Dieter', 'Clarke', 'Ashby', 'Chauncey', 'Nick', 'Ritch', 'Salvidor', 'Niels', 'Osbourn', 'Paddie', 'Sergeant', 'Haywood', 'Kendrick', 'Mike', 'Wash', 'Corwin', 'Wallache', 'Elwood', 'Hiro', 'Jorge', 'Stirling', 'Haskel', 'Job', 'Brody', 'Aristotle', 'Anatole', 'Bubba', 'Carter', 'Jerrome', 'Jeffrey', 'Ulberto', 'Harland', 'Roice', 'Redmond', 'Zacharia', 'Nickey', 'Kevan', 'Antoine', 'Armando', 'Che', 'Sloan', 'Herrick', 'Simmonds', 'Conroy', 'David', 'Townie', 'Gerard', 'Marwin', 'Matthew', 'Zary', 'Herschel', 'Keenan', 'Shurlocke', 'Verney', 'Jules']\n"
     ]
    }
   ],
   "source": [
    "print(male[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Балансируем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oversampling!\n",
    "missing = len(female) - len(male)\n",
    "male += male[:missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffling\n",
    "import random\n",
    "random.shuffle(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 4636\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7416 1856 7416 1856\n"
     ]
    }
   ],
   "source": [
    "boundary = int(len(female) * 0.8)\n",
    "x_train = female[:boundary] + male[:boundary]\n",
    "x_test = female[boundary:] + male[boundary:]\n",
    "y_train = ['female'] * (boundary ) + ['male'] * (boundary)\n",
    "y_test = ['female'] * (len(x_test)//2) + ['male'] * (len(x_test)//2)\n",
    "print(len(x_train), len(x_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>Benoite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Filide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>Gretal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>Shauna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>Elwira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class     name\n",
       "0  female  Benoite\n",
       "1  female   Filide\n",
       "2  female   Gretal\n",
       "3  female   Shauna\n",
       "4  female   Elwira"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "index = random.sample(range(len(x_train)), len(x_train))\n",
    "df = pd.DataFrame({'name': x_train, 'class': y_train})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>Josie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>Barris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>Tamarah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>Teador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>Salomone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class      name\n",
       "0  female     Josie\n",
       "1    male    Barris\n",
       "2  female   Tamarah\n",
       "3    male    Teador\n",
       "4    male  Salomone"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перемешаем\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 2. Базовая \n",
    "\n",
    "### Базовый метод классификации [3 балла]\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from nltk.util import ngrams\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_ngrams(n):\n",
    "#     return [list(ngrams(name, n)) for name in df.name]\n",
    "# df['bigrams'] = [list(''.join(ng) for ng in ngrams(name, 2)) for name in df.name]\n",
    "# df['trigrams'] = [list(ngrams(name, 3)) for name in df.name]\n",
    "# df['quadrigrams'] = [list(ngrams(name, 4)) for name in df.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg = TfidfVectorizer(ngram_range=(2,2), analyzer='char')\n",
    "mat_trg = stg.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(mat_trg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = nb.predict(stg.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.73      0.80      0.76       928\n",
      "       male       0.78      0.70      0.74       928\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=default_preprocessor)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 3. Нейросетевая \n",
    "\n",
    "### Нейронная сеть [5 баллов]\n",
    "\n",
    "\n",
    "Используйте  реккурентную нейронную сеть с  LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM).  У нейронной сети один выход, определяющий класс имени. \n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$ – то есть, используется one hot encoding.  \n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами. \n",
    "\n",
    "Сравните результаты классификации разными методами. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совсем не получается запрограммировать нейронную сеть самостоятельно, обратитесь к туториалу тут: https://github.com/divamgupta/lstm-gender-predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### делаем one-hot-encoded данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = sorted(set(''.join(df['name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(df['name'].map(lambda x: len(x)))\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(data, letters, maxlen):\n",
    "    '''np.array вида (кол-во примеров х бинарная матрица размера (количество букв в алфавите × максимальная длина имени)'''\n",
    "    res = np.zeros((len(data), maxlen, len(letters)))\n",
    "    for i in range(len(data)): # по именам\n",
    "        for l in range(len(data[i])): # по буквам\n",
    "            res[i][l][letters.index(data[i][l])] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7416, 15, 55)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = one_hot(x_train, alphabet, maxlen)\n",
    "y_train = np.array(list(map(lambda x: (1, 0) if x=='female' else (0, 1), y_train)))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### а теперь собственно модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train, y_train, batch_size=len(X_train), epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = one_hot(x_test, alphabet, maxlen)\n",
    "y_test = to_categorical(np.array(list(map(lambda x: 0 if x=='female' else 1, y_test))), num_classes=2)\n",
    "preds = model.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.82      0.80       928\n",
      "          1       0.81      0.78      0.79       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.796875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(y_test, preds))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.81      0.80       928\n",
      "          1       0.81      0.77      0.79       928\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1856\n",
      "\n",
      "0.7914870689655172\n"
     ]
    }
   ],
   "source": [
    "# другие методы\n",
    "# добавляем дропаут\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds = model.predict(X_test, verbose=0)\n",
    "preds = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80       928\n",
      "          1       0.80      0.80      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.8033405172413793\n"
     ]
    }
   ],
   "source": [
    "# меняем значение дропаута\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds2 = model.predict(X_test, verbose=0)\n",
    "preds2 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds2)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds2))\n",
    "print(accuracy_score(y_test, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.82      0.79       928\n",
      "          1       0.80      0.75      0.78       928\n",
      "\n",
      "avg / total       0.79      0.79      0.79      1856\n",
      "\n",
      "0.7855603448275862\n"
     ]
    }
   ],
   "source": [
    "# один LSTM-слой\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = False, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds3 = model.predict(X_test, verbose=0)\n",
    "preds3 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds3)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds3))\n",
    "print(accuracy_score(y_test, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.82      0.81       928\n",
      "          1       0.81      0.79      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.8033405172413793\n"
     ]
    }
   ],
   "source": [
    "# меняем количество узлов\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds4 = model.predict(X_test, verbose=0)\n",
    "preds4 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds4)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds4))\n",
    "print(accuracy_score(y_test, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.80      0.80       928\n",
      "          1       0.80      0.80      0.80       928\n",
      "\n",
      "avg / total       0.80      0.80      0.80      1856\n",
      "\n",
      "0.7990301724137931\n"
     ]
    }
   ],
   "source": [
    "# меняем количество слоёв\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences = True, input_shape=(maxlen, len(alphabet))))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = False))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose=0)\n",
    "    \n",
    "preds5 = model.predict(X_test, verbose=0)\n",
    "preds5 = np.array(list(map(lambda x: [1., 0.] if x[0]>x[1] else [0., 1.], preds5)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds5))\n",
    "print(accuracy_score(y_test, preds5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог: ничего не меняется! Только лучше два LSTM-слоя, чем один. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elsbeth [1. 0.]\n",
      "Oreste [1. 0.]\n",
      "Jonell [1. 0.]\n",
      "Violet [1. 0.]\n",
      "Margery [1. 0.]\n",
      "Shel [1. 0.]\n",
      "Ingaborg [1. 0.]\n",
      "Nicol [1. 0.]\n",
      "Deerdre [1. 0.]\n",
      "Hali [1. 0.]\n",
      "Venus [1. 0.]\n",
      "Jenifer [1. 0.]\n",
      "Orel [1. 0.]\n",
      "Rakel [1. 0.]\n",
      "Deirdre [1. 0.]\n",
      "Wanda [1. 0.]\n",
      "Taryn [1. 0.]\n",
      "Nance [1. 0.]\n",
      "Merci [1. 0.]\n",
      "Prudence [1. 0.]\n",
      "Becky [1. 0.]\n",
      "Beilul [1. 0.]\n",
      "Bekki [1. 0.]\n",
      "Idell [1. 0.]\n",
      "Ines [1. 0.]\n",
      "Carrol [1. 0.]\n",
      "Pier [1. 0.]\n",
      "Katheryn [1. 0.]\n",
      "Vere [1. 0.]\n",
      "Burta [1. 0.]\n",
      "Gates [1. 0.]\n",
      "Marjy [1. 0.]\n",
      "Vicky [1. 0.]\n",
      "Shandy [1. 0.]\n",
      "Valma [1. 0.]\n",
      "Nova [1. 0.]\n",
      "Raven [1. 0.]\n",
      "Damaris [1. 0.]\n",
      "Ame [1. 0.]\n",
      "Mavis [1. 0.]\n",
      "Mitzi [1. 0.]\n",
      "Inger [1. 0.]\n",
      "Brunhilde [1. 0.]\n",
      "Milicent [1. 0.]\n",
      "Mommy [1. 0.]\n",
      "Deloris [1. 0.]\n",
      "Sukey [1. 0.]\n",
      "Farand [1. 0.]\n",
      "Harri [1. 0.]\n",
      "Greer [1. 0.]\n",
      "Francesca [1. 0.]\n",
      "Steffane [1. 0.]\n",
      "Kimberly [1. 0.]\n",
      "Audre [1. 0.]\n",
      "Ardith [1. 0.]\n",
      "Midge [1. 0.]\n",
      "Stormi [1. 0.]\n",
      "Marijo [1. 0.]\n",
      "Meghan [1. 0.]\n",
      "Beatriz [1. 0.]\n",
      "Betty [1. 0.]\n",
      "Mignon [1. 0.]\n",
      "Tiff [1. 0.]\n",
      "Sharl [1. 0.]\n",
      "Windy [1. 0.]\n",
      "Sileas [1. 0.]\n",
      "Cher [1. 0.]\n",
      "Trudey [1. 0.]\n",
      "Storey [1. 0.]\n",
      "Eadith [1. 0.]\n",
      "Gwendolyn [1. 0.]\n",
      "Jacynth [1. 0.]\n",
      "Reggi [1. 0.]\n",
      "Vikkie [1. 0.]\n",
      "Glennis [1. 0.]\n",
      "Suzie [1. 0.]\n",
      "Sheryl [1. 0.]\n",
      "Ambur [1. 0.]\n",
      "Prue [1. 0.]\n",
      "Maris [1. 0.]\n",
      "Riki [1. 0.]\n",
      "Dorris [1. 0.]\n",
      "Estell [1. 0.]\n",
      "Tabbi [1. 0.]\n",
      "Vicki [1. 0.]\n",
      "Pauly [1. 0.]\n",
      "Tamar [1. 0.]\n",
      "Ermengarde [1. 0.]\n",
      "Inge [1. 0.]\n",
      "Jewel [1. 0.]\n",
      "Joann [1. 0.]\n",
      "Dotty [1. 0.]\n",
      "Madlen [1. 0.]\n",
      "Batsheva [1. 0.]\n",
      "Hatty [1. 0.]\n",
      "Robbi [1. 0.]\n",
      "Mercedes [1. 0.]\n",
      "Mallory [1. 0.]\n",
      "Maryrose [1. 0.]\n",
      "Dode [1. 0.]\n",
      "Robyn [1. 0.]\n",
      "Dawn [1. 0.]\n",
      "Marys [1. 0.]\n",
      "Tove [1. 0.]\n",
      "Consuelo [1. 0.]\n",
      "Marcy [1. 0.]\n",
      "Alyson [1. 0.]\n",
      "Rosamund [1. 0.]\n",
      "Bamby [1. 0.]\n",
      "Caron [1. 0.]\n",
      "Sapphire [1. 0.]\n",
      "Becca [1. 0.]\n",
      "Bridgett [1. 0.]\n",
      "Nariko [1. 0.]\n",
      "Genevieve [1. 0.]\n",
      "Sheril [1. 0.]\n",
      "Ester [1. 0.]\n",
      "Mildrid [1. 0.]\n",
      "Nicholle [1. 0.]\n",
      "Constancy [1. 0.]\n",
      "Elonore [1. 0.]\n",
      "Hedi [1. 0.]\n",
      "Nicolle [1. 0.]\n",
      "Dorthy [1. 0.]\n",
      "Olva [1. 0.]\n",
      "Zara [1. 0.]\n",
      "Yoko [1. 0.]\n",
      "Joyous [1. 0.]\n",
      "Noell [1. 0.]\n",
      "Leonore [1. 0.]\n",
      "Babs [1. 0.]\n",
      "Ursa [1. 0.]\n",
      "Suzi [1. 0.]\n",
      "Riannon [1. 0.]\n",
      "Wilone [1. 0.]\n",
      "Easter [1. 0.]\n",
      "Andromache [1. 0.]\n",
      "Dulci [1. 0.]\n",
      "Bee [1. 0.]\n",
      "Lamb [1. 0.]\n",
      "Tish [1. 0.]\n",
      "Prudy [1. 0.]\n",
      "Truda [1. 0.]\n",
      "Diahann [1. 0.]\n",
      "Megen [1. 0.]\n",
      "Stoddard [1. 0.]\n",
      "Taffy [1. 0.]\n",
      "Vi [1. 0.]\n",
      "Brigid [1. 0.]\n",
      "Bab [1. 0.]\n",
      "Dusty [1. 0.]\n",
      "Ethelind [1. 0.]\n",
      "Charlot [1. 0.]\n",
      "Hermione [1. 0.]\n",
      "Orly [1. 0.]\n",
      "Avivah [1. 0.]\n",
      "Gwendolen [1. 0.]\n",
      "Fabrice [1. 0.]\n",
      "Malory [1. 0.]\n",
      "Heather [1. 0.]\n",
      "Flower [1. 0.]\n",
      "Vikky [1. 0.]\n",
      "Sue [1. 0.]\n",
      "Jorry [1. 0.]\n",
      "Marris [1. 0.]\n",
      "Ulla [1. 0.]\n",
      "Arden [1. 0.]\n",
      "Ricca [1. 0.]\n",
      "Olwen [1. 0.]\n",
      "Adore [1. 0.]\n",
      "Shawna [1. 0.]\n",
      "Gaynor [1. 0.]\n",
      "Susann [1. 0.]\n",
      "Judi [1. 0.]\n",
      "Ruth [1. 0.]\n",
      "Gerty [1. 0.]\n",
      "Jessamyn [1. 0.]\n",
      "Hedwig [1. 0.]\n",
      "Tammi [1. 0.]\n",
      "Suzan [1. 0.]\n",
      "Sharyl [1. 0.]\n",
      "Charis [1. 0.]\n",
      "Petronille [1. 0.]\n",
      "Leanor [1. 0.]\n",
      "Starr [1. 0.]\n",
      "Dwaine [0. 1.]\n",
      "Tanny [0. 1.]\n",
      "Kent [0. 1.]\n",
      "Matthieu [0. 1.]\n",
      "Noble [0. 1.]\n",
      "Giovanne [0. 1.]\n",
      "Samuele [0. 1.]\n",
      "Scottie [0. 1.]\n",
      "Constantin [0. 1.]\n",
      "Mathias [0. 1.]\n",
      "Gabriele [0. 1.]\n",
      "Beale [0. 1.]\n",
      "Arne [0. 1.]\n",
      "Neale [0. 1.]\n",
      "Arel [0. 1.]\n",
      "Mayer [0. 1.]\n",
      "Conroy [0. 1.]\n",
      "Lonny [0. 1.]\n",
      "Sebastien [0. 1.]\n",
      "Israel [0. 1.]\n",
      "Mattias [0. 1.]\n",
      "Gabe [0. 1.]\n",
      "Arne [0. 1.]\n",
      "Tanney [0. 1.]\n",
      "Hussein [0. 1.]\n",
      "Sebastiano [0. 1.]\n",
      "Carlyle [0. 1.]\n",
      "Gordan [0. 1.]\n",
      "Boniface [0. 1.]\n",
      "Alastair [0. 1.]\n",
      "Partha [0. 1.]\n",
      "Manny [0. 1.]\n",
      "Gabe [0. 1.]\n",
      "Meier [0. 1.]\n",
      "Nelsen [0. 1.]\n",
      "Brian [0. 1.]\n",
      "Stevie [0. 1.]\n",
      "Erny [0. 1.]\n",
      "Colin [0. 1.]\n",
      "Hyatt [0. 1.]\n",
      "Alan [0. 1.]\n",
      "Morley [0. 1.]\n",
      "Cain [0. 1.]\n",
      "Felipe [0. 1.]\n",
      "Paddie [0. 1.]\n",
      "Jake [0. 1.]\n",
      "Clinten [0. 1.]\n",
      "Lucian [0. 1.]\n",
      "Tanney [0. 1.]\n",
      "Joshua [0. 1.]\n",
      "Kennedy [0. 1.]\n",
      "Elijah [0. 1.]\n",
      "Natale [0. 1.]\n",
      "Cleland [0. 1.]\n",
      "Florian [0. 1.]\n",
      "Kin [0. 1.]\n",
      "Michael [0. 1.]\n",
      "Jonny [0. 1.]\n",
      "Adair [0. 1.]\n",
      "Jonny [0. 1.]\n",
      "Solly [0. 1.]\n",
      "Roni [0. 1.]\n",
      "Clive [0. 1.]\n",
      "Obadiah [0. 1.]\n",
      "Augie [0. 1.]\n",
      "Danie [0. 1.]\n",
      "Dougie [0. 1.]\n",
      "Broddie [0. 1.]\n",
      "Brinkley [0. 1.]\n",
      "Sollie [0. 1.]\n",
      "Aditya [0. 1.]\n",
      "Micheil [0. 1.]\n",
      "Lennie [0. 1.]\n",
      "Avi [0. 1.]\n",
      "Johnathan [0. 1.]\n",
      "Jamey [0. 1.]\n",
      "Sebastiano [0. 1.]\n",
      "Len [0. 1.]\n",
      "Israel [0. 1.]\n",
      "Nolan [0. 1.]\n",
      "Archie [0. 1.]\n",
      "Louie [0. 1.]\n",
      "Nealy [0. 1.]\n",
      "Cobbie [0. 1.]\n",
      "Mace [0. 1.]\n",
      "Natale [0. 1.]\n",
      "Barnabe [0. 1.]\n",
      "Keil [0. 1.]\n",
      "Pascale [0. 1.]\n",
      "Duane [0. 1.]\n",
      "Nikita [0. 1.]\n",
      "Dabney [0. 1.]\n",
      "Sinclare [0. 1.]\n",
      "Andri [0. 1.]\n",
      "Tye [0. 1.]\n",
      "Dylan [0. 1.]\n",
      "Abe [0. 1.]\n",
      "Hyatt [0. 1.]\n",
      "Jermayne [0. 1.]\n",
      "Andreas [0. 1.]\n",
      "Elias [0. 1.]\n",
      "Guy [0. 1.]\n",
      "Clint [0. 1.]\n",
      "Lemmie [0. 1.]\n",
      "Davey [0. 1.]\n",
      "Isaak [0. 1.]\n",
      "Emilio [0. 1.]\n",
      "Blayne [0. 1.]\n",
      "Alastair [0. 1.]\n",
      "Dabney [0. 1.]\n",
      "Mortie [0. 1.]\n",
      "Bennett [0. 1.]\n",
      "Jonathan [0. 1.]\n",
      "Dyson [0. 1.]\n",
      "Ari [0. 1.]\n",
      "Jimmy [0. 1.]\n",
      "Dino [0. 1.]\n",
      "Lloyd [0. 1.]\n",
      "Lay [0. 1.]\n",
      "Chase [0. 1.]\n",
      "Thorndike [0. 1.]\n",
      "Voltaire [0. 1.]\n",
      "Tremain [0. 1.]\n",
      "Jeremie [0. 1.]\n",
      "Dimitri [0. 1.]\n",
      "Chrisy [0. 1.]\n",
      "Glynn [0. 1.]\n",
      "Gere [0. 1.]\n",
      "Chip [0. 1.]\n",
      "Adlai [0. 1.]\n",
      "Dante [0. 1.]\n",
      "Maximilian [0. 1.]\n",
      "Riley [0. 1.]\n",
      "Ulysses [0. 1.]\n",
      "Clarke [0. 1.]\n",
      "Zollie [0. 1.]\n",
      "Tyrone [0. 1.]\n",
      "Amory [0. 1.]\n",
      "Garey [0. 1.]\n",
      "Corbin [0. 1.]\n",
      "Amery [0. 1.]\n",
      "Izzy [0. 1.]\n",
      "Paddie [0. 1.]\n",
      "Nathanael [0. 1.]\n",
      "Dwayne [0. 1.]\n",
      "Chaddie [0. 1.]\n",
      "Irvine [0. 1.]\n",
      "Stanley [0. 1.]\n",
      "Tannie [0. 1.]\n",
      "Levi [0. 1.]\n",
      "Noe [0. 1.]\n",
      "Lloyd [0. 1.]\n",
      "Dudley [0. 1.]\n",
      "Doyle [0. 1.]\n",
      "Jake [0. 1.]\n",
      "Isidore [0. 1.]\n",
      "Zacharia [0. 1.]\n",
      "Dimitry [0. 1.]\n",
      "Hezekiah [0. 1.]\n",
      "Rollin [0. 1.]\n",
      "Rustie [0. 1.]\n",
      "Fonsie [0. 1.]\n",
      "Clyde [0. 1.]\n",
      "Pasquale [0. 1.]\n",
      "Blare [0. 1.]\n",
      "Brady [0. 1.]\n",
      "Bentley [0. 1.]\n",
      "Jory [0. 1.]\n",
      "Grady [0. 1.]\n",
      "Huntlee [0. 1.]\n",
      "Toddie [0. 1.]\n",
      "Mateo [0. 1.]\n",
      "Neddie [0. 1.]\n",
      "Chrisy [0. 1.]\n",
      "Elroy [0. 1.]\n",
      "Barney [0. 1.]\n",
      "Ferdinand [0. 1.]\n",
      "Kalil [0. 1.]\n",
      "Dylan [0. 1.]\n",
      "Dean [0. 1.]\n",
      "Keene [0. 1.]\n",
      "Christiano [0. 1.]\n",
      "Silvain [0. 1.]\n",
      "Sebastian [0. 1.]\n",
      "Charley [0. 1.]\n",
      "Izaak [0. 1.]\n",
      "Keene [0. 1.]\n",
      "Gere [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_test)):\n",
    "    if all(y_test[i] != preds5[i]):\n",
    "        print(x_test[i], y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 4. Сомнительная \n",
    "\n",
    "### Визуализация [5 баллов]\n",
    "\n",
    "Побочным продуктом обучения нейронной сети будут эмбеддинги символов – 26 векторов для всех букв латинского алфавита. Попробуйте использовать разные методы снижения размерности – SVD или TSNE – и изобразить точки, соответствующие разным символам, на плоскости. Получаются ли осмысленные и интерпретируемые кластеры? "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "maga",
   "language": "python",
   "name": "maga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
