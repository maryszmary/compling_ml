{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 3 [10 баллов]\n",
    "\n",
    "\n",
    "# До 27.03.18 23:59\n",
    "\n",
    "Рассмотрим задачу бинарной классификации. Пусть дано два списка имен: мужские и женские имена. Требуется разработать классификатор, который по данному имени будет определять мужское оно или женское.\n",
    "\n",
    "Данные: \n",
    "* Женские имена: female.txt\n",
    "* Мужские имена: male.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Предварительная\n",
    "\n",
    "### Предварительная обработка данных [2 балла]\n",
    "\n",
    "1. Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть; \n",
    "2. Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 2943\n"
     ]
    }
   ],
   "source": [
    "# прочитаем файлы\n",
    "female = open('female.txt', 'r').read().split('\\n')\n",
    "male = open('male.txt', 'r').read().split('\\n')\n",
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Удаляем неоднозначные имена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# найдем имена, которые одинаковы для двух списков\n",
    "result = set(female) & set(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# удалим их!\n",
    "female = list(set(female) - result)\n",
    "male = list(set(male) - result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 2578\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kimmo', 'Higgins', 'Briggs', 'Yigal', 'Adnan', 'Sherlocke', 'Osgood', 'Alessandro', 'Godart', 'Rudolfo', 'Izak', 'Bennett', 'Dieter', 'Rock', 'Diego', 'Alvin', 'Hiralal', 'Torr', 'Jef', 'Sim', 'Jerold', 'Herrmann', 'Upton', 'Peyton', 'Claudius', 'Davin', 'Kenny', 'Tarrant', 'Vinod', 'Engelbart', 'Quinton', 'Rik', 'Noach', 'Randal', 'Andrey', 'Emil', 'Bard', 'Waylan', 'Spud', 'Ross', 'Ez', 'Ernie', 'Whitaker', 'Terence', 'Swen', 'Praneetf', 'Chaddy', 'Vassili', 'Hansel', 'Sheffie', 'Merell', 'Sheppard', 'Rob', 'Siegfried', 'Hillery', 'Wilden', 'Horatio', 'Chadd', 'Tuckie', 'Stan', 'Peyter', 'Walsh', 'Norbert', 'Mohammed', 'Sergeant', 'Calvin', 'Wat', 'Guido', 'Verne', 'Rowland', 'Zared', 'Silvester', 'Taber', 'Hymie', 'Nunzio', 'Clinten', 'Witold', 'Terencio', 'Barnaby', 'Pyotr', 'Mic', 'Hamnet', 'Lon', 'Erhart', 'Johan', 'Izaak', 'Adams', 'Lance', 'Clifford', 'Buster', 'Otho', 'Ritch', 'Steve', 'Garold', 'Xerxes', 'Zackariah', 'Rab', 'Ruddy', 'Aldwin', 'Milt']\n"
     ]
    }
   ],
   "source": [
    "print(male[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Балансируем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# oversampling!\n",
    "missing = len(female) - len(male)\n",
    "male += male[:missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4636 4636\n"
     ]
    }
   ],
   "source": [
    "print(len(female), len(male))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 2. Базовая \n",
    "\n",
    "### Базовый метод классификации [3 балла]\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?\n",
    "\n",
    "Для генерации $n$-грамм используйте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 3. Нейросетевая \n",
    "\n",
    "### Нейронная сеть [4 балла]\n",
    "\n",
    "\n",
    "Используйте  реккурентную нейронную сеть с  LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM).  У нейронной сети один выход, определяющий класс имени. \n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$ – то есть, используется one hot encoding.  \n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами. \n",
    "\n",
    "Сравните результаты классификации разными методами. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если совсем не получается запрограммировать нейронную сеть самостоятельно, обратитесь к туториалу тут: https://github.com/divamgupta/lstm-gender-predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import LSTM, TimeDistributed, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# бинарная матрица размера (количество букв в алфавите × максимальная длина имени)\n",
    "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "# model.add(TimeDistributed(Dense(len(alphabet)+2, activation = 'softmax'))) # может быть потом я пойму зачем это\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train,y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# другие методы\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train,y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 0)\n",
    "    \n",
    "preds = model.predict(X_test, verbose=0)[0]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(alphabet)+2, 30, input_length=maxlen))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "for iteration in range(1, 100):\n",
    "    X_train_shuffled, y_train_shuffled = shuffle(X_train,y_train)\n",
    "    model.fit(X_train_shuffled, y_train_shuffled, batch_size=len(X_train), epochs=1, verbose = 0)\n",
    "    \n",
    "preds = model.predict(X_test, verbose=0)[0]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Часть 4. Сомнительная \n",
    "\n",
    "### Визуализация [1 балл]\n",
    "\n",
    "Побочным продуктом обучения нейронной сети будут эмбеддинги символов – 26 векторов для всех букв латинского алфавита. Попробуйте использовать разные методы снижения размерности – SVD или TSNE – и изобразить точки, соответствующие разным символам, на плоскости. Получаются ли осмысленные и интерпретируемые кластеры? "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
