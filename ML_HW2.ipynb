{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание по ML №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка\n",
    "\n",
    "> **Задание**: Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. \n",
    "Ответьте на следующие вопросы:\n",
    "1. Есть ли корреляция между средней длинной текста за день и DJIA?\n",
    "2. Есть ли корреляция между количеством упоминаний Барака Обамы и США в день и DJIA? Учтите разные варианты написания США.\n",
    "3. Каких статей больше: статей о России и Путине или об Исламском государстве (запрещенной законом РФ террористическая организации)?\n",
    "4. О каких кризисах (crisis) пишут статьи?\n",
    "\n",
    "\n",
    "Импортируем библиотеки. Для успешной работы с данными должны быть установлены следующие библиотеки:\n",
    "* numpy\n",
    "* pandas\n",
    "* sklearn\n",
    "* matplotlib\n",
    "* nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные, смотрим на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('Combined_News_DJIA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...   \n",
       "1  b'An American citizen living in S.Ossetia blam...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...   \n",
       "3             b'Russian forces sink Georgian ships '   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "2                        ...                           \n",
       "3                        ...                           \n",
       "4                        ...                           \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь положим все топики в один столбец для удобства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Remember that adorable 9-year-old who sang at the opening ceremonies? That was fake, too. Russia \\'ends Georgia operation\\' \"If we had no sexual harassment we would have no children...\" Al-Qa\\'eda is losing support in Iraq because of a brutal crackdown on activities it regards as un-Islamic - including women buying cucumbers Ceasefire in Georgia: Putin Outmaneuvers the West Why Microsoft and Intel tried to kill the XO $100 laptop Stratfor: The Russo-Georgian War and the Balance of Power    I\\'m Trying to Get a Sense of This Whole Georgia-Russia War: Vote Up If You Think Georgia Started It, Or Down If you Think Russia Did The US military was surprised by the timing and swiftness of the Russian military\\'s move into South Ossetia and is still trying to sort out what happened, a US defense official said Monday U.S. Beats War Drum as Iran Dumps the Dollar Gorbachev: \"Georgian military attacked the South Ossetian capital of Tskhinvali with multiple rocket launchers designed to devastate large areas\" CNN use footage of Tskhinvali ruins to cover Georgian report [VIDEO] Beginning a war as the Olympics were opening violates the ancient tradition of a truce to conflict during the Games.  The IOC could respond by taking the 2014 games away from Russia. 55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay The 11 Top Party Cities in the World U.S. troops still in Georgia (did you know they were in Georgia in the first place?) Why Russias response to Georgia was right Gorbachev accuses U.S. of making a \"serious blunder\" in pursuing its interest in the Caucasus region Russia, Georgia, and NATO: Cold War Two Remember that adorable 62-year-old who led your country into war based on evidence? That was fake, too. War in Georgia: The Israeli connection All signs point to the US encouraging Georgia to invade South Ossetia. Goddamnit Bush. Christopher King argues that the US and NATO are behind the Georgian invasion of South Ossetia but have misjudged Russian resolve.  America: The New Mexico? BBC NEWS | Asia-Pacific | Extinction \\'by man not climate\\''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# функункция для избавления от b\"...\" в данных (оказавшихся там из-за неправильного сохранения?)\n",
    "def beautify_string(s):\n",
    "    return s[2:-1] if type(s) is not float else ''\n",
    "    \n",
    "# функция для объединения данных столбцов с топиками в один столбец\n",
    "def merge_topics(sli):\n",
    "    return ' '.join([beautify_string(s) for s in sli])\n",
    "\n",
    "merge_topics(df_news.iloc[2, 2:27]) # смёрдженные топики второго столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# итерируем строки датафрейма и склеиваем содержание нужных столбцов, запиываем результат в новый стоблец\n",
    "df_news['topics'] = [merge_topics(df_news.iloc[row, 2:27]) for row in df_news.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq? Bush puts foot down on Georgian conflict Jewish Georgian minister: Thanks to Israeli training, we\\'re fending off Russia  Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired Olympic opening ceremony fireworks \\'faked\\' What were the Mossad with fraudulent New Zealand Passports doing in Iraq? Russia angered by Israeli military sale to Georgia An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people Welcome To World War IV! Now In High Definition! Georgia\\'s move, a mistake of monumental proportions  Russia presses deeper into Georgia; U.S. says regime change is goal Abhinav Bindra wins first ever Individual Olympic Gold Medal for India  U.S. ship heads for Arctic to define territory Drivers in a Jerusalem taxi station threaten to quit rather than work for their new boss - an Arab The French Team is Stunned by Phelps and the 4x100m Relay Team Israel and the US behind the Georgian aggression? \"Do not believe TV, neither Russian nor Georgian. There are much more victims\" Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday. China to overtake US as largest manufacturer War in South Ossetia [PICS] Israeli Physicians Group Condemns State Torture  Russia has just beaten the United States over the head with Peak Oil Perhaps *the* question about the Georgia - Russia conflict  Russia is so much better at war So this is what it\\'s come to: trading sex for food.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас мы сделаем пробную предобработку текстов, чтобы продемонстрировать пример предобработки и ответить на вопросы из задания.\n",
    "\n",
    "Стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopset = stopwords.words('english')\n",
    "stopset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пунктуация:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punct = list(punctuation)\n",
    "punct[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BREAKING', ':', 'Musharraf', 'to', 'be', 'impeached']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы не будем лемматизировать заголовки новостей, потому что <s>этот лемматизатор в nltk как мёртвому припарка</s> <s>чувак-победитель на kaggle ничего не лемматизировал</s> информация о словоизменении может оказаться полезной.\n",
    "\n",
    "Теперь определим общую функцию для предобработки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [w for w in text if w not in stopset + punct] # убираем стоп-слова и пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breaking', 'musharraf', 'impeached']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [georgia, 'downs, two, russian, warplanes, cou...\n",
       "1    [wont, america, nato, help, us, wont, help, us...\n",
       "2    [remember, adorable, 9-year-old, sang, opening...\n",
       "3    [u.s., refuses, israel, weapons, attack, iran,...\n",
       "4    [experts, admit, legalise, drugs, war, south, ...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(default_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**А что если оставить стоп-слова?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stopwords_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [w for w in text if w not in punct] # убираем пунктуацию, оставляем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breaking', 'musharraf', 'to', 'be', 'impeached']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [georgia, 'downs, two, russian, warplanes, as,...\n",
       "1    [why, wont, america, and, nato, help, us, if, ...\n",
       "2    [remember, that, adorable, 9-year-old, who, sa...\n",
       "3    [u.s., refuses, israel, weapons, to, attack, i...\n",
       "4    [all, the, experts, admit, that, we, should, l...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(stopwords_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оставим только пунктуацию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [w for w in text if w not in stopset] # убираем стоп-слова, оставляем пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breaking', ':', 'musharraf', 'impeached']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [georgia, 'downs, two, russian, warplanes, ', ...\n",
       "1    [wont, america, nato, help, us, ?, wont, help,...\n",
       "2    [remember, adorable, 9-year-old, sang, opening...\n",
       "3    [u.s., refuses, israel, weapons, attack, iran,...\n",
       "4    [experts, admit, legalise, drugs, war, south, ...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(punct_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**оставим только различие регистров**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_preprocessor(text):\n",
    "    text = word_tokenize(text) # токенизируем и НЕ приводим к нижнему регистру \n",
    "    return [w for w in text if w not in stopset + punct] # убираем стоп-слова и пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BREAKING', 'Musharraf', 'impeached']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Georgia, 'downs, two, Russian, warplanes, cou...\n",
       "1    [Why, wont, America, Nato, help, us, If, wont,...\n",
       "2    [Remember, adorable, 9-year-old, sang, opening...\n",
       "3    [U.S., refuses, Israel, weapons, attack, Iran,...\n",
       "4    [All, experts, admit, legalise, drugs, War, So...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(lower_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оставим знаки препинания + стопслова**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_punct_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['breaking', ':', 'musharraf', 'to', 'be', 'impeached']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_punct_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [georgia, 'downs, two, russian, warplanes, ', ...\n",
       "1    [why, wont, america, and, nato, help, us, ?, i...\n",
       "2    [remember, that, adorable, 9-year-old, who, sa...\n",
       "3    [u.s., refuses, israel, weapons, to, attack, i...\n",
       "4    [all, the, experts, admit, that, we, should, l...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(stop_punct_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оставим стоп-слова + регистр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_lower_preprocessor(text):\n",
    "    text = word_tokenize(text) # токенизируем\n",
    "    return [w for w in text if w not in punct] # убираем пунктуацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BREAKING', 'Musharraf', 'to', 'be', 'impeached']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_lower_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Georgia, 'downs, two, Russian, warplanes, as,...\n",
       "1    [Why, wont, America, and, Nato, help, us, If, ...\n",
       "2    [Remember, that, adorable, 9-year-old, who, sa...\n",
       "3    [U.S., refuses, Israel, weapons, to, attack, I...\n",
       "4    [All, the, experts, admit, that, we, should, l...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(stop_lower_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оставим знаки препинания + регистр**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_lower_preprocessor(text):\n",
    "    text = word_tokenize(text) # токенизируем\n",
    "    return [w for w in text if w not in stopset] # убираем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BREAKING', ':', 'Musharraf', 'impeached']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_lower_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Georgia, 'downs, two, Russian, warplanes, ', ...\n",
       "1    [Why, wont, America, Nato, help, us, ?, If, wo...\n",
       "2    [Remember, adorable, 9-year-old, sang, opening...\n",
       "3    [U.S., refuses, Israel, weapons, attack, Iran,...\n",
       "4    [All, experts, admit, legalise, drugs, War, So...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(punct_lower_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Только токенизируем!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BREAKING', ':', 'Musharraf', 'to', 'be', 'impeached']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Georgia, 'downs, two, Russian, warplanes, ', ...\n",
       "1    [Why, wont, America, and, Nato, help, us, ?, I...\n",
       "2    [Remember, that, adorable, 9-year-old, who, sa...\n",
       "3    [U.S., refuses, Israel, weapons, to, attack, I...\n",
       "4    [All, the, experts, admit, that, we, should, l...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(word_tokenize)[:5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование данных\n",
    "\n",
    "#### 1. Есть ли корреляция между средней длинной текста за день и DJIA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы воспользовались функцией, которая считает коэффициент корреляции Пирсона в модуле numpy https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для объединения данных столбцов с топиками в один массив\n",
    "def merge_topics_2arr(sli):\n",
    "    arr = [beautify_string(s) for s in sli]\n",
    "    return(arr)\n",
    "\n",
    "# итерируем строки датафрейма и склеиваем содержание нужных столбцов, запиываем результат в новый стоблец\n",
    "df_news['topics_list'] = [merge_topics_2arr(df_news.iloc[row, 2:27]) for row in df_news.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# посчитали среднюю длину текста за день\n",
    "res = []\n",
    "for topics in df_news['topics_list']:\n",
    "    arr = [len(topic) for topic in topics]\n",
    "    res.append(sum(arr)/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# добавили в датафрейм новый столбец\n",
    "df_news['av_len'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0027900870985365146"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь посчитаем коэффициент корреляции Пирсона\n",
    "# 1 способ\n",
    "np.corrcoef(df_news['Label'], df_news['av_len'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr = -0.00279008709854 p_value = 0.901034281785\n"
     ]
    }
   ],
   "source": [
    "# 2 способ\n",
    "from scipy.stats import pearsonr\n",
    "x = df_news['Label']\n",
    "y = df_news['av_len']\n",
    "corr, p_value = pearsonr(x, y)\n",
    "\n",
    "print('corr =', corr, 'p_value =', p_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коэффициент корреляции Пирсона – это мера скоррелированности двух переменных. Он принимает значения от 1 до –1, где 1 означает, что корреляция между переменными идеальна, 0 – что корреляции нет, а –1, что имеется идеальная обратная корреляция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае результат близок к нулю, так что можно сказать, что корреляции между средней длинной текста за день и DJIA не наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Есть ли корреляция между количеством упоминаний Барака Обамы и США в день и DJIA? Учтите разные варианты написания США."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать, что одно+ упоминание имени барака обамы и/или сша в топике = одно упоминание в день"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "America = ['United States of America', 'America', 'US', 'USA', 'U.S.', 'Barack', 'Obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# подсчитаем, в скольких топиках за день упоминается америка или барак обама\n",
    "def is_x(arr):\n",
    "    is_x = []\n",
    "    for topics in df_news['topics_list']:\n",
    "        n = 0\n",
    "        for topic in topics:\n",
    "            i = 0\n",
    "            for word in arr:\n",
    "                if word in topic:\n",
    "                    i += 1\n",
    "            if i>0:\n",
    "                n += 1\n",
    "        is_x.append(n)\n",
    "    return(is_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news['is_america'] = is_x(America)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.1548429719110349e-05"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь посчитаем коэффициент корреляции Пирсона\n",
    "# 1 способ\n",
    "np.corrcoef(df_news['is_america'], df_news['Label'])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr = -3.15484297191e-05 p_value = 0.998878079838\n"
     ]
    }
   ],
   "source": [
    "# 2 способ\n",
    "from scipy.stats import pearsonr\n",
    "x = df_news['Label']\n",
    "y = df_news['is_america']\n",
    "corr, p_value = pearsonr(x, y)\n",
    "\n",
    "print('corr =', corr, 'p_value =', p_value )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "коэффициент корреляции приблизительно равен -0.00003154842. Т.е. он тоже стремится к нулю, что значит, что корреляции нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Каких статей больше: статей о России и Путине или об Исламском государстве (запрещенной законом РФ террористическая организации)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Russia = ['Russian Federation', 'Russia', 'RF', 'Putin']\n",
    "ISIL = ['Islamic State', 'ISIL', 'ISIS', 'IS', 'Daesh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news['is_russia'] = is_x(Russia)\n",
    "df_news['is_isil'] = is_x(ISIL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russia = 2054 ISIL = 1017\n"
     ]
    }
   ],
   "source": [
    "print('russia =', sum(df_news['is_russia']), 'ISIL =', sum(df_news['is_isil']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про Россию и Путина статей больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. О каких кризисах (crisis) пишут статьи?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crisis_preprocessor(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    arr = [w for w in text if w not in stopset + punct] # убираем стоп-слова и пунктуацию\n",
    "    return ' '.join(arr) # склеиваем вс1 в строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breaking musharraf impeached'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crisis_preprocessor('BREAKING: Musharraf to be impeached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "crs = []\n",
    "for topics in df_news['topics_list']:\n",
    "    for topic in topics:\n",
    "        topic = crisis_preprocessor(topic)\n",
    "        if 'crisis' in topic:\n",
    "            cr = re.findall('[a-zA-Z]+ crisis', topic)\n",
    "            for i in cr:\n",
    "                crs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449 189\n"
     ]
    }
   ],
   "source": [
    "print(len(crs), len(set(crs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for cr in crs:\n",
    "    if cr not in d:\n",
    "        d[cr] = 1\n",
    "    else:\n",
    "        d[cr] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "financial crisis - 48\n",
      "economic crisis - 25\n",
      "debt crisis - 21\n",
      "food crisis - 17\n",
      "raine crisis - 14\n",
      "ukraine crisis - 12\n",
      "nuclear crisis - 12\n",
      "political crisis - 9\n",
      "euro crisis - 9\n",
      "humanitarian crisis - 9\n",
      "refugee crisis - 9\n",
      "banking crisis - 7\n",
      "s crisis - 7\n",
      "ria crisis - 7\n",
      "migrant crisis - 6\n",
      "grant crisis - 4\n",
      "fugee crisis - 4\n",
      "eurozone crisis - 4\n",
      "water crisis - 4\n",
      "health crisis - 4\n",
      "global crisis - 4\n",
      "za crisis - 4\n",
      "currency crisis - 3\n",
      "cholera crisis - 3\n",
      "aq crisis - 3\n",
      "climate crisis - 3\n",
      "greek crisis - 3\n",
      "reached crisis - 3\n",
      "syria crisis - 3\n",
      "bank crisis - 3\n",
      "energy crisis - 3\n",
      "korea crisis - 3\n",
      "eek crisis - 3\n",
      "fa crisis - 2\n",
      "current crisis - 2\n",
      "oil crisis - 2\n",
      "diplomatic crisis - 2\n",
      "thai crisis - 2\n",
      "warns crisis - 2\n",
      "men crisis - 2\n",
      "response crisis - 2\n",
      "rape crisis - 2\n",
      "pan crisis - 2\n",
      "lanka crisis - 2\n",
      "housing crisis - 2\n",
      "crimea crisis - 2\n",
      "ola crisis - 2\n",
      "hostage crisis - 2\n",
      "gration crisis - 2\n",
      "ebola crisis - 2\n",
      "iraq crisis - 2\n",
      "grants crisis - 2\n",
      "iceland crisis - 2\n",
      "fundamental crisis - 1\n",
      "deficit crisis - 1\n",
      "pollution crisis - 1\n",
      "gaza crisis - 1\n",
      "woman crisis - 1\n",
      "extreme crisis - 1\n",
      "li crisis - 1\n",
      "european crisis - 1\n",
      "judiciary crisis - 1\n",
      "wider crisis - 1\n",
      "excess crisis - 1\n",
      "coverage crisis - 1\n",
      "kyrgyzstan crisis - 1\n",
      "grapples crisis - 1\n",
      "mortgage crisis - 1\n",
      "street crisis - 1\n",
      "brewing crisis - 1\n",
      "fukushima crisis - 1\n",
      "population crisis - 1\n",
      "profits crisis - 1\n",
      "lessons crisis - 1\n",
      "orphan crisis - 1\n",
      "paying crisis - 1\n",
      "including crisis - 1\n",
      "exploit crisis - 1\n",
      "rubbish crisis - 1\n",
      "child crisis - 1\n",
      "jeapordised crisis - 1\n",
      "blame crisis - 1\n",
      "banks crisis - 1\n",
      "dementia crisis - 1\n",
      "mounting crisis - 1\n",
      "coast crisis - 1\n",
      "drugs crisis - 1\n",
      "end crisis - 1\n",
      "fix crisis - 1\n",
      "identity crisis - 1\n",
      "redshirts crisis - 1\n",
      "good crisis - 1\n",
      "possible crisis - 1\n",
      "althcare crisis - 1\n",
      "legal crisis - 1\n",
      "russia crisis - 1\n",
      "cucumber crisis - 1\n",
      "ldives crisis - 1\n",
      "part crisis - 1\n",
      "ammunition crisis - 1\n",
      "cash crisis - 1\n",
      "world crisis - 1\n",
      "difficult crisis - 1\n",
      "seeker crisis - 1\n",
      "worsening crisis - 1\n",
      "rwandan crisis - 1\n",
      "silent crisis - 1\n",
      "nuke crisis - 1\n",
      "banon crisis - 1\n",
      "profit crisis - 1\n",
      "korean crisis - 1\n",
      "bleaching crisis - 1\n",
      "infanticide crisis - 1\n",
      "cause crisis - 1\n",
      "troops crisis - 1\n",
      "potential crisis - 1\n",
      "treatment crisis - 1\n",
      "yen crisis - 1\n",
      "total crisis - 1\n",
      "unveiling crisis - 1\n",
      "rebels crisis - 1\n",
      "survey crisis - 1\n",
      "kunar crisis - 1\n",
      "rrency crisis - 1\n",
      "rozone crisis - 1\n",
      "superbug crisis - 1\n",
      "covering crisis - 1\n",
      "syrian crisis - 1\n",
      "paradise crisis - 1\n",
      "monarchy crisis - 1\n",
      "cedonian crisis - 1\n",
      "price crisis - 1\n",
      "wetland crisis - 1\n",
      "lifetime crisis - 1\n",
      "ypt crisis - 1\n",
      "wed crisis - 1\n",
      "year crisis - 1\n",
      "darfur crisis - 1\n",
      "week crisis - 1\n",
      "pakistan crisis - 1\n",
      "budget crisis - 1\n",
      "icelands crisis - 1\n",
      "close crisis - 1\n",
      "funding crisis - 1\n",
      "unveils crisis - 1\n",
      "market crisis - 1\n",
      "huge crisis - 1\n",
      "demographic crisis - 1\n",
      "count crisis - 1\n",
      "change crisis - 1\n",
      "time crisis - 1\n",
      "christians crisis - 1\n",
      "reef crisis - 1\n",
      "selling crisis - 1\n",
      "escalation crisis - 1\n",
      "signs crisis - 1\n",
      "avert crisis - 1\n",
      "reaches crisis - 1\n",
      "rma crisis - 1\n",
      "arab crisis - 1\n",
      "phosphorus crisis - 1\n",
      "google crisis - 1\n",
      "caucasus crisis - 1\n",
      "economy crisis - 1\n",
      "gender crisis - 1\n",
      "apologize crisis - 1\n",
      "italian crisis - 1\n",
      "credibility crisis - 1\n",
      "radiation crisis - 1\n",
      "serious crisis - 1\n",
      "unemployment crisis - 1\n",
      "jobs crisis - 1\n",
      "credit crisis - 1\n",
      "says crisis - 1\n",
      "nancial crisis - 1\n",
      "migration crisis - 1\n",
      "brink crisis - 1\n",
      "georgian crisis - 1\n",
      "indeed crisis - 1\n",
      "hunger crisis - 1\n",
      "looming crisis - 1\n",
      "uk crisis - 1\n",
      "tensions crisis - 1\n",
      "ukrainian crisis - 1\n",
      "ivoire crisis - 1\n",
      "marriage crisis - 1\n",
      "east crisis - 1\n",
      "word crisis - 1\n",
      "uses crisis - 1\n"
     ]
    }
   ],
   "source": [
    "for slovo in sorted(d, key = d.get, reverse = True):\n",
    "    print(slovo + ' - ' + str(d[slovo]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из представленного частотного списка, самые обсуждаемые -- это financial crisis и economic crisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификаторов\n",
    "\n",
    "> **Задание**: Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится DJIA. То есть, метки класса (y) заданы DJIA, признаки (X) требуется извлечь из текстов.\n",
    "\n",
    "> Обучающее и тестовое множество строится так: данные до начала 2015 года используются для обучения, данные с 2015 года и позже – для тестирования.\n",
    "\n",
    "> Используйте любой известный вам алгоритм классификации текстов для того,  Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure  для оценки качества классификации. Покажите, как  $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации. \n",
    "\n",
    "> Если у выбранного вами алгоритма есть гиперпараметры (например, alpha в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на train и test, как сказано в задании:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df_news[df_news['Date'] < '2015-01-01']\n",
    "test = df_news[df_news['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008-08-08, 2014-12-31\n"
     ]
    }
   ],
   "source": [
    "print(train.iloc[0]['Date'] + ', ' + train.iloc[-1]['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-02 2016-07-01\n"
     ]
    }
   ],
   "source": [
    "print(test.iloc[0]['Date'], test.iloc[-1]['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сначала деревья решений, CountVectorizer и наш дефолтный препроцессинг:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...        min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=default_preprocessor)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.48      0.50       186\n",
      "          1       0.53      0.57      0.55       192\n",
      "\n",
      "avg / total       0.53      0.53      0.53       378\n",
      "\n",
      "0.526455026455\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, дефолтный вариант работает очень плохо: результаты практически не отличаются от подбрасывания монетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем немного поиграться с параметрами: зададим минимальную/максимальную частоту документа, другой ngram_range, максимальное количество листьев..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...        min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=default_preprocessor, min_df=5)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.50      0.51       186\n",
      "          1       0.54      0.56      0.55       192\n",
      "\n",
      "avg / total       0.53      0.53      0.53       378\n",
      "\n",
      "0.531746031746\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже немного лучше! Немного поэксперементировав, поняли, что оптимальная минимальная частота — 5, а вот максимальную лучше не трогать. Попытки подобрать максимальное количество листьев и оптимальный разброс нграммов успехом не увенчались.\n",
    "\n",
    "А теперь попробуем использовать TfidfVectorizer вместо CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.45      0.46       186\n",
      "          1       0.49      0.51      0.50       192\n",
      "\n",
      "avg / total       0.48      0.48      0.48       378\n",
      "\n",
      "0.478835978836\n"
     ]
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', TfidfVectorizer(tokenizer=default_preprocessor)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=45))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)\n",
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, $tf-idf$ преобразование делает вещи хуже! (Проверено на random_state от 35 до 45 и с разными значениями min_df и max_df, вверху — лучший результат, которого получилось добиться).\n",
    "\n",
    "Вернёмся к обычному CountVectorizer и теперь попробуем другой препроцессинг. Например, попробуем не убирать стоп-слова (а только пунктуацию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.41      0.44       186\n",
      "          1       0.49      0.55      0.52       192\n",
      "\n",
      "avg / total       0.48      0.48      0.48       378\n",
      "\n",
      "0.484126984127\n"
     ]
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=stopwords_preprocessor)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)\n",
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, лучше не становится. (Тоже проверено при разных параметрах).\n",
    "\n",
    "А теперь попробуем использовать лемматизатор<s> и понять, почему не надо этого делать</s>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'added'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitten'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('kittens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'longer'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('longer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Как мы видим, лемматизируются только существительные, всё остальное не лемматизируется. Попробуем всё же применить этот лемматизатор в действии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['georgia', \"'downs\", 'two', 'russian', 'warplanes', 'countries']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemm_preproc(text):\n",
    "    text = wnl.lemmatize(text)\n",
    "    return default_preprocessor(text)\n",
    "lemm_preproc(train.topics[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.50      0.51       186\n",
      "          1       0.54      0.56      0.55       192\n",
      "\n",
      "avg / total       0.53      0.53      0.53       378\n",
      "\n",
      "0.531746031746\n"
     ]
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=lemm_preproc, min_df=5)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)\n",
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо, результат особенно не изменился.\n",
    "\n",
    "А что если вместо лемматизации с помощью WordNetLemmatizer воспользоваться стемматизацией с SnowballStemmer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s = SnowballStemmer(\"english\")\n",
    "s.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['georgia', 'down', 'two', 'russian', 'warplan', 'countri']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_preproc(text):\n",
    "    text = word_tokenize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [s.stem(w) for w in text if w not in stopset + punct] # - стоп-слова и пунктуация, + стемминг\n",
    "stem_preproc(train.topics[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, эта работает лучше! Применим её на практике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.35      0.40       186\n",
      "          1       0.48      0.57      0.52       192\n",
      "\n",
      "avg / total       0.46      0.47      0.46       378\n",
      "\n",
      "0.465608465608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.38      0.43       186\n",
      "          1       0.50      0.60      0.55       192\n",
      "\n",
      "avg / total       0.49      0.49      0.49       378\n",
      "\n",
      "0.492063492063\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.42      0.46       186\n",
      "          1       0.51      0.59      0.55       192\n",
      "\n",
      "avg / total       0.51      0.51      0.50       378\n",
      "\n",
      "0.507936507937\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.39      0.43       186\n",
      "          1       0.50      0.59      0.54       192\n",
      "\n",
      "avg / total       0.49      0.49      0.49       378\n",
      "\n",
      "0.492063492063\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.40      0.44       186\n",
      "          1       0.51      0.60      0.55       192\n",
      "\n",
      "avg / total       0.50      0.50      0.49       378\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.41      0.45       186\n",
      "          1       0.52      0.60      0.56       192\n",
      "\n",
      "avg / total       0.51      0.51      0.51       378\n",
      "\n",
      "0.510582010582\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    ppl = Pipeline(\n",
    "        [('vect', CountVectorizer(tokenizer=stem_preproc, min_df=i)),\n",
    "        ('tree', DecisionTreeClassifier(random_state=42))]\n",
    "    )\n",
    "    ppl.fit(train.topics, y=train.Label)\n",
    "    print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "    print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет, тоже не помогло.\n",
    "\n",
    "Попробуем теперь какую-нибудь другую модель, например, логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.40      0.33      0.36       186\n",
      "          1       0.44      0.52      0.48       192\n",
      "\n",
      "avg / total       0.42      0.43      0.42       378\n",
      "\n",
      "0.425925925926\n"
     ]
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=default_preprocessor, min_df=5)),\n",
    "    ('tree', LogisticRegression(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)\n",
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Получается, деревья решений лучше, чем логистическая регрессия. Потестим все функции препроцессинга (токенизации), которые описаны в пункте 1, с деревьями решений + CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...        min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=word_tokenize, min_df=5)),\n",
    "    ('tree', DecisionTreeClassifier(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.46      0.49       186\n",
      "          1       0.53      0.60      0.56       192\n",
      "\n",
      "avg / total       0.53      0.53      0.53       378\n",
      "\n",
      "0.529100529101\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебрав все функции препроцессинга мы выяснили, что лучшей является дефолтная функция, которая убирает стоп-слова, знаки препинания и приводит всё к нижнему регистру (с одной оговоркой: разница в регистре не влияет на результат по сравнению с дефолтным токенизатором). \n",
    "Остальные функции препроцессинга делают результат только хуже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3 [2 балла] Творческая\n",
    "> Придумайте и попытайтесь сделать еще что-нибудь, чтобы улучшить качество классификации. Например:\n",
    "* использовать в качестве признаков только именованные сущности;\n",
    "* использовать в качестве признаков скрытые темы;\n",
    "* добавить признак, отвечающий за какие-то важные темы или тональность новостей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Именнованые сущности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def names_preprocessor(text):\n",
    "    text = re.sub('^[A-Za-z]+ ', '', text) # убираем первое слово в предложении\n",
    "    text = re.sub('\\. [A-Za-z]+ ', '. ', text)\n",
    "    res = re.findall('[A-Z][a-z]+', text)\n",
    "    arr = [w for w in res if w.lower() not in stopset]\n",
    "    if arr == []:\n",
    "        return None\n",
    "    else:\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Musharraf', 'Rala', 'Nya', 'Cococo']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_preprocessor('Lalala BREAKING: Musharraf to Be Rala impeached Nya. Lalal rara Cococo.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_preprocessor('rara ococo ldfb. lkdfv dfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Russian, Musharraf, Today, Columns, South, Os...\n",
       "1    [America, Nato, Iraq, Bush, Georgian, Jewish, ...\n",
       "2    [Georgia, Al, Qa, Iraq, Islamic, Ceasefire, Ge...\n",
       "3    [Israel, Iran, Tskhinvali, South, Ossetia, Isr...\n",
       "4    [War, South, Osetia, Russian, Ara, Abrahamian,...\n",
       "Name: topics, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.topics.map(names_preprocessor)[:5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-e71d7b809df4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     ('tree', LogisticRegression(random_state=42))]\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    221\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    587\u001b[0m                        **fit_params):\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "ppl = Pipeline(\n",
    "    [('vect', CountVectorizer(tokenizer=names_preprocessor, min_df=5)),\n",
    "    ('tree', LogisticRegression(random_state=42))]\n",
    ")\n",
    "ppl.fit(train.topics, y=train.Label)\n",
    "print(classification_report(test.Label, ppl.predict(test.topics)))\n",
    "print(accuracy_score(test.Label, ppl.predict(test.topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
