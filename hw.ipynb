{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(1228)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "я бы поставила семь, конечно, но можно и три пока а это для последнего задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 1800\n",
    "VOCABULARY_SIZE = 250000\n",
    "EMBEDDING_DIM = 300\n",
    "DIMS = 250\n",
    "MAX_FEATURES = 5000\n",
    "batch_size = 32\n",
    "\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(train_corpus.body)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: написать train_corpus и test_corpus\n",
    "\n",
    "TODO: куда писать размер окна????!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_corpus.body)\n",
    "X_train = tokenizer.sequences_to_matrix(sequences, mode='count')\n",
    "sequences = tokenizer.texts_to_sequences(test_corpus.body)\n",
    "X_test = tokenizer.sequences_to_matrix(sequences, mode='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лейблэнкодер делает one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_corpus.topic.unique())\n",
    "y_train = np_utils.to_categorical(le.transform(train_corpus.topic), 5)\n",
    "y_test = np_utils.to_categorical(le.transform(test_corpus.topic), 5)\n",
    "y_true = le.transform(test_corpus.topic)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нелинейная функция скрытого слоя – ReLU (для старта)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(VOCABULARY_SIZE, EMBEDDING_DIM, input_length=TEXT_LENGTH))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation = 'relu')) # скрытый слой; TODO: что такое первый аргумент (кол-во нейронов??)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation = 'softmax')) # софтмакс для классификации\n",
    "# добавить one-hot??\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(k, n, theta):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCABULARY_SIZE, EMBEDDING_DIM, input_length=TEXT_LENGTH))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(n, activation = theta)) # скрытый слой; TODO: посмотреть, что ткое первый аргумент\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation = 'softmax')) # TODO: написать кол-во классов\n",
    "    # добавить one-hot??\n",
    "    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
